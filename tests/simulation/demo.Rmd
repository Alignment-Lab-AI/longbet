---
title: "Comparing LongBet with baseline methods"
author: "Maggie Wang"
date: "`r Sys.Date()`"
output: pdf_document
---

# Comparing LongBet with baseline methods on staggered adoption design

**Note: this is not supposed to be an evaluation of the different estimators/packages.** Load packages.

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
# devtools::install_github('MaggieWang0614/longbet')
require(longbet)
require(dplyr)
require(ggplot2)
require(tidyr)
require(panelView)
require(stringr)
require(MetBrewer)
# baseline approach
require(did) # https://github.com/bcallaway11/did
require(fixest)
require(didimputation)
require(plm)
```

First, we create a simulated data set, with pre-treatment covariates, staggered treatments, heterogeneous and dynamic treatment effects. The pre-treatment covariates and heterogeneity are based on dgp in the BCF paper. There are 5 pre-treatment covariates, three are continuous variables and two are categorical variables. The dynamic prognostic effect is simulated from an ARIMA(1, 0, 1) model and the dynamic treatment effect is a decaying function. The staggered adoption is sampled from propensity score. Consider a total of 12 periods with 5 pre-treatment periods, the staggerd adoption starts at period 6.

```{r sim data}
source('dgp.R')
n = 2000
t0 = 6
t1 = 12
pr_type = "non-parallel"
trt_type = "heterogeneous"
alpha = 0.05
data <- dgp(n, t0, t1, pr_type = pr_type, trt_type = trt_type)

# get training data
ytrain <- data$y
ztrain <- data$z
xtrain <- data$x

# stack data
first.treat <- t1 - rowSums(ztrain) + 1
first.treat[first.treat == t1 + 1] <- 0
panel.data <- data.frame(
  ytrain = as.vector( t(ytrain) ),
  ztrain = as.vector( t(ztrain) ),
  first.treat = as.vector( sapply(first.treat, rep, t1)),
  id = as.vector( sapply(1:n, rep, t1)),
  time = rep(1:t1, n),
  X1 = as.vector( sapply(xtrain[,1], rep, t1)),
  X2 = as.vector( sapply(xtrain[,2], rep, t1)),
  X3 = as.vector( sapply(xtrain[,3], rep, t1)),
  X4 = as.vector( sapply(xtrain[,4], rep, t1)),
  X5 = as.vector( sapply(xtrain[,5], rep, t1))
)
# align treatment effect
align_tau <- matrix(NA, nrow = n, ncol = t1 - t0 + 1)
for (i in 1:n){
  if (sum(ztrain[i,]) == 0) {next}
  align_tau[i, 1:sum(ztrain[i,])] = data$tau[i, ztrain[i,] == 1]
} 

att <- colMeans(align_tau, na.rm = T)
att.df <- data.frame(
  t = 0:(t1 - t0),
  estimate = att,
  conf.low = att,
  conf.high = att,
  method = rep("True", t1 - t0 + 1)
)

att.results <- data.frame(
  method = character(),
  RMSE = double(),
  Bias = double(),
  Coverage = double(),
  Cover0 = double(),
  I.L = double()
)

catt.results <- data.frame(
    method = character(),
    RMSE = double(),
    Bias = double(),
    Coverage = double(),
    Cover0 = double(),
    I.L = double()
  )

```

We can plot the data and treatment status using Licheng Liu and Yiqing Xu's awesome `panelView` package [@liu.2021.panelview].

```{r plot treatment, warnings=FALSE}
panelview(ytrain ~ ztrain, data = panel.data, index = c("id","time"), xlab = "Time", ylab = "Unit", axis.lab.gap = 5, display.all = T)
```

Check parallel trend assumption
```{r parallel}
# Estimate a fixed-effects panel regression model for the untreated group only
untreated_model <- plm(ytrain ~ time + time:ztrain, 
                       data = panel.data[panel.data$ztrain == 0,], 
                       index = c("id", "time"),
                       model = "within")

# View the summary of the untreated model
summary(untreated_model)

```

First we estimate the treatment effect with LongBet

```{r longbet}
longbet.time <- proc.time()
longbet.fit <- longbet(y = ytrain, x = xtrain, z = ztrain, t = 1:t1,
                       num_sweeps = 120,
                       num_trees_pr =  20, num_trees_trt = 20,
                       pcat = ncol(xtrain) - 3)

longbet.pred <- predict.longbet(longbet.fit, xtrain, ztrain)
# align catt
num_sweeps <- dim(longbet.pred$tauhats)[3]
align_catt <- array(NA, dim = c(n, t1 - t0 + 1, num_sweeps))
for (i in 1:n){
  if (sum(ztrain[i,]) == 0) {next}
  align_catt[i, 1:sum(ztrain[i,]), ] = longbet.pred$tauhats[i, ztrain[i,] == 1, ]
} 

longbet.att <- align_catt %>%
  apply(c(2, 3), mean, na.rm = T) %>% t() %>%
  data.frame() %>%
  gather("t", "CATT") %>%
  mutate(t =  as.double(str_replace_all(t, c("X" = ""))) - 1) %>%
  group_by(t) %>%
  summarise(
    estimate = mean(CATT),
    conf.low = quantile(CATT, prob = alpha / 2),
    conf.high = quantile(CATT, prob = 1 - alpha / 2),
    method = "LongBet"
  )

longbet.catt <- apply(align_catt, c(1, 2), mean, na.rm = T)
      longbet.catt.low <- apply(align_catt, c(1, 2), quantile, prob = alpha /2 , na.rm = T)
      longbet.catt.high <- apply(align_catt, c(1, 2), quantile, prob = 1 - alpha /2 , na.rm = T)
      
att.results[nrow(att.results) + 1,] <- c('LongBet', att.metric(att, longbet.att))
catt.results[nrow(catt.results) + 1, ] <- c('LongBet', catt.metric(align_tau, longbet.catt, longbet.catt.low, longbet.catt.high))

print(att.results)
      
```

We then estimate the treatment effect using DiD with multiple periods.

```{r did}
did.time <- proc.time()
did.out <- att_gt(yname = "ytrain",
              gname = "first.treat",
              idname = "id",
              tname = "time",
              xformla = ~ X1 + X3 + X2 + X4 + X5,
              data = panel.data,
              est_method = "dr",
              control_group = "notyettreated"
)
DiD <- aggte(did.out, type = "dynamic", na.rm = TRUE) %>% 
  tidy() %>% 
  rename(t = event.time) %>% 
  filter(t >= 0 & t < 8) %>% 
  select(t, estimate, conf.low, conf.high) %>% 
  mutate(method = "DiD")
did.time <- proc.time() - did.time

att.results[nrow(att.results) + 1,] <- c('DiD', att.metric(att, DiD))
```

We can also supply the DiD method with known relationship in covariates for non-linear prognostic effects.

```{r did non-linear}
did_nl.time <- proc.time()
if (pr_type == "linear"){
  did_nl.out <- att_gt(yname = "ytrain",
                gname = "first.treat",
                idname = "id",
                tname = "time",
                xformla = ~ X1 + X3 + X2 + X4 + X5,
                data = panel.data,
                est_method = "dr",
                control_group = "notyettreated"
  )
} else {
  did_nl.out <- att_gt(yname = "ytrain",
              gname = "first.treat",
              idname = "id",
              tname = "time",
              xformla = ~ X1 * X3 + X2 + X4 + X5,
              data = panel.data,
              est_method = "dr",
              control_group = "notyettreated")
}

DiD_nl <- aggte(did_nl.out, type = "dynamic", na.rm = TRUE) %>% 
  tidy() %>% 
  rename(t = event.time) %>% 
  filter(t >= 0 & t < 8) %>% 
  select(t, estimate, conf.low, conf.high) %>% 
  mutate(method = "Non-linear DiD")
did_nl.time = proc.time() - did_nl.time

att.results[nrow(att.results) + 1,] <- c('Non-linear DiD', att.metric(att, DiD_nl))
```

The following is an implementation of the did_imputation method kindly shared by Eray Turkel from Google. But since borusyak already have a package for did_impuation in R, we are not going to run the following method.
```{r twfe}
#Imputation approach from borusyak, jaravel, spiess 2021
# Take your panel data set, divide it into two, one being the ‘untreated’ control #observations (including the pre-treatment data for the eventually treated #subset), and the #other one being the ‘treated’ # # observations. The expectation is #that #the ‘treated’ units #will appear in both data frames, their pre-treatment #observations will 
#be in the #’control_obs’ and the post-treatment observations will be in the #‘treated_obs’
#the two input data frames control_obs,
#treated_obs should be ‘long’ data frames with
#’uniq_id’ which is the unit id,
#’panel_time’ which is the ‘absolute time’ variable for the panel ranging from 1 to the end #time,
#’move_date’ which is the absolute time period which the treatment started, for each treated #observation
#’event_time’ which is the ‘time past since treatment start’ for the treated observations.
# and an ‘outcome’ for each time period, as well as any time constant covariates #’cov1,cov2,cov3’ etc.
#Weights vec is the weighting vector for each observation- useful for bootstrap inference #down the line

imp.data <- data.frame(
  outcome = as.vector( t(ytrain) ),
  treat_status = as.vector( t(ztrain) ),
  uniq_id = as.vector( sapply(1:n, rep, t1)),
  panel_time = rep(1:t1, n),
  move_date = as.vector( sapply(first.treat, rep, t1)),
  cov1 = as.vector( sapply(xtrain[,1], rep, t1)),
  cov2 = as.vector( sapply(xtrain[,2], rep, t1)),
  cov3 = as.vector( sapply(xtrain[,3], rep, t1)),
  cov4 = as.vector( sapply(xtrain[,4], rep, t1)),
  cov5 = as.vector( sapply(xtrain[,5], rep, t1))
)
imp.data$event_time <- sapply(imp.data$panel_time - imp.data$move_date + 1, function(x) max(x, 0))
imp.data$event_time[imp.data$move_date == 0] <- 0

imp.data$X1 <- cut(imp.data$cov1, breaks = 20, labels = 1:20)
imp.data$X2 <- cut(imp.data$cov2, breaks = 20, labels = 1:20)
imp.data$X3 <- cut(imp.data$cov3, breaks = 20, labels = 1:20)


estimate_event_time_effects_weighted<-function(control_obs,treated_obs,weights_vec, include_cov){
  control_ids<-unique(control_obs$uniq_id)
  treated_ids<-unique(treated_obs$uniq_id)
  
  status_changers<-intersect(control_ids, treated_ids)
  treated_obs%>%filter(uniq_id %in% status_changers)->imputed_group
  
  #Add more interactions of panel_time with covariates here as needed
  if (include_cov){
    fixed_effect_object<-fixest::feols(outcome ~ -1 | uniq_id + panel_time^cov4^cov5^X1^X2^X3, data=control_obs, weights = weights_vec)
  } else{
    fixed_effect_object<-fixest::feols(outcome ~ -1 | uniq_id + panel_time, data=control_obs, weights = weights_vec)
  }
  predicted_outcome<-predict(fixed_effect_object,newdata=imputed_group)
  imputed_group$counterfactual_outcome<-predicted_outcome
  imputed_group$tau_est<-imputed_group$outcome-imputed_group$counterfactual_outcome
  
  imputed_group%>%
    group_by(event_time)%>%
    summarise(period_effect=mean(tau_est,na.rm = TRUE))->event_time_estimates
  
  return(list(event=event_time_estimates,individual=imputed_group))
}

#Main function to do bootstrap inference for effects
boot_BJS_effects<-function(dataset,period_number,boot_number, alpha, include_cov){
  parentids<-unique(dataset$uniq_id)
  individual_frame<-data.frame()
  event_frame<-data.frame()
  control_obs<-dataset[dataset$treat_status==0,]
  treated_obs<-dataset[dataset$treat_status ==1,]
  control_obs%>%arrange(uniq_id)->control_obs
  control_obs%>%select(uniq_id)%>%table()->obs_counts
  for(i in (1:boot_number)){
    weight_vector<-rep(rexp(nrow(obs_counts)), obs_counts)
    BJS_results<-estimate_event_time_effects_weighted(control_obs,treated_obs,weight_vector, include_cov)
    event_study_estimates<-BJS_results$event
    event_study_estimates$boot_id<-i
    event_study_estimates<-dplyr::bind_rows(event_study_estimates,
                                            data.frame(event_time=9999,period_effect=sum(event_study_estimates$period_effect)))
    individual_estimates<-BJS_results$individual
    individual_estimates$boot_id<-i
    event_frame<-dplyr::bind_rows(event_frame,event_study_estimates)
    individual_frame<-dplyr::bind_rows(individual_frame,individual_estimates)
  }
  
  event_frame %>%
    group_by(event_time) %>% 
    summarise(conf.low=quantile(period_effect,alpha / 2,na.rm = TRUE),
              estimate = mean(period_effect, na.rm = TRUE),
              conf.high=quantile(period_effect, 1 - alpha / 2,na.rm = TRUE)) %>%
    rename(t = event_time) %>%
    mutate(method = "DiD Imputation FE")  %>%
    mutate(t = t - 1) %>%
    filter(t >= 0 & t < 999) ->event_effects
  
  # individual_frame%>%group_by(move_date,event_time)%>%summarise(low=quantile(tau_est,alpha / 2,na.rm = TRUE),
  #                                                               high=quantile(tau_est,1-alpha/2,na.rm = TRUE))->cohort_per_period_effects
  # 
  # individual_frame%>%group_by(move_date)%>%summarise(low=quantile(total_effect,alpha/2,na.rm = TRUE),
  #                                                    high=quantile(total_effect,1-alpha/2,na.rm = TRUE))->cohort_total_effects
  # 
  # results_list=list(
  #   event_times=event_effects,
  #   cohort_period=cohort_per_period_effects,
  #   cohort_total=cohort_total_effects
  # )
  return (event_effects)}

# did_imp_check <- boot_BJS_effects(imp.data, t1, 200, alpha, include_cov = FALSE)
# did_imp_check %>% mutate(method = "DiD Imputation Check")

did_imp_fe <- boot_BJS_effects(imp.data, t1, 200, alpha, include_cov = TRUE)

att.results[nrow(att.results) + 1,] <- c('DiD Imputation Cov', att.metric(att, did_imp_fe))

```

DiD imputation approach implemented in borusyak, jaravel, spiess 2021.
```{r did impute}
did_imp.fit <- did_imputation(data = panel.data, yname = "ytrain", gname = "first.treat",
                          tname = "time", idname = "id", 
                          first_stage = ~ 0 | id + time,
                          horizon=TRUE) 
print(did_imp.fit)
did_imp <- did_imp.fit %>% 
  select(t = term, estimate, std.error) %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error,
    t = as.numeric(t)
  ) %>%
  mutate(method = "DiD Imputation") %>% 
  select(c(t, estimate, conf.low, conf.high, method)) %>% 
  filter(t >= 0 & t < 8)
att.results[nrow(att.results) + 1,] <- c('DiD Imputation', att.metric(att, did_imp))

```
Although Susan Athey's paper discussed incorporating covariates with matrix completion method, the MCPanel package does not offer the option for covariates. And fitting without covariates can not get any reasonable estimation in this dgp.

```{r matrix completion}
# library(MCPanel)
# ytrain.mask <- ytrain * ztrain
# mcnnm.fit <- mcnnm_cv(ytrain, ztrain, to_estimate_u = 1, to_estimate_v = 1)
# mcnnm.fit$est <- mcnnm.fit$L + replicate(t1,mcnnm.fit$u) + t(replicate(n,mcnnm.fit$v))
# mcnnm.fit$catt <- matrix(NA, nrow = n, ncol = t1 - t0 + 1)
# for (i in 1:n){
#   if (sum(ztrain[i,]) == 0) {next}
#   mcnnm.fit$catt[i, 1:sum(ztrain[i,])] = ytrain[i, ztrain[i, ] == 1] - mcnnm.fit$est[i, ztrain[i,] == 1]
# }
# 
# mcnnm.att <- mcnnm.fit$catt %>%
#   data.frame() %>%
#   gather("t", "CATT") %>%
#   mutate(t =  as.double(str_replace_all(t, c("X" = ""))) - 1) %>%
#   group_by(t) %>%
#   summarise(
#     estimate = mean(CATT, na.rm = TRUE),
#     method = "MC"
#   )
# mcnnm.att
```

Visualization

```{r plot}
coefs <- bind_rows(att.df, longbet.att, DiD, DiD_nl, did_imp, did_imp_fe)

plot <- coefs %>% 
  ggplot(aes(x = t, y = estimate, color = method)) + 
  geom_point(aes(x = t, y = estimate), position = position_dodge2(width = 0.8), size = 1) +
  geom_linerange(aes(x = t, ymin = conf.low, ymax = conf.high), position = position_dodge2(width = 0.8), size = 0.75) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red", size = .25, alpha = 0.75) + 
  geom_vline(xintercept = -0.5, linetype = "dashed", size = .25) +
  scale_color_manual(name="Estimation Method", values= met.brewer("Cross", 8, "discrete")) +
  theme(legend.position= 'bottom') +
  labs(title = 'Event Time Estimates', y="ATT", x = "Relative Time") + 
  guides(col = guide_legend(nrow = 3)) 
print(plot)
```

```{r}
print(att.results)
print(catt.results)
```
